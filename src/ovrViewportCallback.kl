/*
 *  Copyright 2010-2014 Fabric Software Inc. All rights reserved.
 */

require InlineDrawing:">1.0.0";
require SpliceStandalone:">1.0.0";
require Singletons;

object ovrViewportCallback : ViewportCallback {
  ovrDevice device;
  ovrDescription desc;
  Color bgColor;
  UInt32 fbo[];
  UInt32 fb_width;
  UInt32 fb_height;
  UInt32 fb_tex[];
  UInt32 fb_depth[];
  ovrGLTexture fb_ovr_tex[2];
  ovrGLConfig cfg;
  ovrEyeRenderDesc eye_rdesc[2];
  ovrPose poses[2];

  Float32 poseScale;
  Vec3 walkOffset;
  Quat turnOffset;
  Xfo worldXfo;
  Boolean requiresSetup;
};

function ovrViewportCallback() {
  this.init(null);
}

function ovrViewportCallback(ovrDevice device) {
  this.init(device);
}

function ovrViewportCallback.init!(ovrDevice device) {
  this.device = device;
  if(device)
    this.desc = device.getDescription();
  this.fbo.push(0);
  this.fb_tex.push(0);
  this.fb_depth.push(0);
  this.bgColor = Color(0.7, 0.7, 0.7, 1.0);
  this.poseScale = 10.0;
  this.requiresSetup = false;
}

function ovrViewportCallback.registerForViewport!(String viewportName) {
  InlineDrawing drawing = Singleton_get('InlineDrawing');
  Viewport viewport = drawing.getViewport(viewportName);
  if(viewport) {
    viewport.registerCallback(ViewportDrawPhase_Setup, this);
    viewport.registerCallback(ViewportDrawPhase_Resize, this);
    viewport.registerCallback(ViewportDrawPhase_PreDraw, this);
    viewport.registerCallback(ViewportDrawPhase_Draw, this);
    viewport.registerCallback(ViewportDrawPhase_PostDraw, this);
  }
}

function ovrViewportCallback.registerForViewport!() {
  this.registerForViewport('default');
}

function Boolean ovrViewportCallback.invoke!(ViewportDrawPhase phase, io Viewport viewport, io DrawContext context) {
  SpliceStandaloneViewport vp = viewport;
  if(!vp) {
    setError('The viewport has to be a SpliceStandaloneViewport, since we need access to the windowId.');
    return false;
  }

  switch(phase) {
    case ViewportDrawPhase_Resize: {
      if(!this.requiresSetup)
        break;
    }
    case ViewportDrawPhase_Setup: {

      if(!this.requiresSetup) {
        this.requiresSetup = true;
        break;
      }
      this.requiresSetup = false;

      ovrSize eyeRes[2];
      eyeRes[0] = this.device.getFovTextureSize(ovrEye_Left);
      eyeRes[1] = this.device.getFovTextureSize(ovrEye_Right);
      this.fb_width = eyeRes[0].w + eyeRes[1].w;
      this.fb_height = eyeRes[0].h > eyeRes[1].h ? eyeRes[0].h : eyeRes[1].h;

      glGenFramebuffers(1, this.fbo);
      glGenTextures(1, this.fb_tex);
      glGenRenderbuffers(1, this.fb_depth);
      glBindTexture(GL_TEXTURE_2D, this.fb_tex[0]);
      glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
      glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);        

      glBindFramebuffer(GL_FRAMEBUFFER, this.fbo[0]);

      Data nullData;

      /* create and attach the texture that will be used as a color buffer */
      glBindTexture(GL_TEXTURE_2D, this.fb_tex[0]);
      glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, this.fb_width, this.fb_height, 0, GL_RGBA, GL_UNSIGNED_BYTE, nullData);
      glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, this.fb_tex[0], 0);

      /* create and attach the renderbuffer that will serve as our z-buffer */
      glBindRenderbuffer(GL_RENDERBUFFER, this.fb_depth[0]);
      glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, this.fb_width, this.fb_height);
      glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, this.fb_depth[0]);
      if(glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) {
        setError("incomplete framebuffer!");
      }
      glBindFramebuffer(GL_FRAMEBUFFER, 0);
      report("Created render target: "+this.fb_width+"x"+this.fb_height+", window "+vp.dimensions.x+'x'+vp.dimensions.y);

      /* fill in the ovrGLTexture structures that describe our render target texture */
      for(ovrEyeType i=0; i<ovrEye_Count; i++) {
        this.fb_ovr_tex[i].API = ovrRenderAPI_OpenGL;
        this.fb_ovr_tex[i].TextureSize.w = this.fb_width;
        this.fb_ovr_tex[i].TextureSize.h = this.fb_height;

        /* this next field is the only one that differs between the two eyes */
        this.fb_ovr_tex[i].RenderViewport.Pos.x = i == 0 ? 0 : this.fb_width / 2.0;
        this.fb_ovr_tex[i].RenderViewport.Pos.y = this.fb_height - this.fb_height;
        this.fb_ovr_tex[i].RenderViewport.Size.w = this.fb_width / 2.0;
        this.fb_ovr_tex[i].RenderViewport.Size.h = this.fb_height;
        this.fb_ovr_tex[i].TexId = this.fb_tex[0]; /* both eyes will use the same texture id */
      } 

      this.cfg.API = ovrRenderAPI_OpenGL;
      this.cfg.RTSize.w = vp.dimensions.x;
      this.cfg.RTSize.h = vp.dimensions.y;
      this.cfg.Multisample = 1;      
      this.cfg.Window = vp.windowId;

      /// on windows this will perform direct rendering
      this.device.attachToWindow(this.cfg.Window);

      /* enable low-persistence display and dynamic prediction for lattency compensation */
      this.device.setEnabledCaps(ovrHmdCap_LowPersistence | ovrHmdCap_DynamicPrediction);
      
      /* configure SDK-rendering and enable chromatic abberation correction, vignetting, and
      * timewrap, which shifts the image before drawing to counter any lattency between the call
      * to ovrDevice.getEyePose and ovrDevice.endFrame.
      */
      // Integer dcaps = ovrDistortionCap_Chromatic | ovrDistortionCap_Vignette | ovrDistortionCap_TimeWarp | ovrDistortionCap_Overdrive;
      Integer dcaps = ovrDistortionCap_Chromatic | ovrDistortionCap_Vignette | ovrDistortionCap_Overdrive;
      // Integer dcaps = 0;
      if(!this.device.configureRendering(this.cfg, dcaps, this.desc.DefaultEyeFov, this.eye_rdesc)) {
        setError("Failed to configure distortion renderer.");
      }

      /* disable the retarded "health and safety warning" */
      this.device.enableHSWDisplaySDKRender(false);
      
      glEnable(GL_DEPTH_TEST);
      glClearColor(this.bgColor.r, this.bgColor.g, this.bgColor.b, this.bgColor.a);

      // if(!vp.gridInstance)
      // {
      //   // setup the grid
      //   InlineDrawing drawing = OGLInlineDrawing_GetInstance();

      //   InlineDebugShape grid = drawing.registerShape(InlineDebugShape('StandaloneGrid'));

      //   Scalar scale = 2.0;
      //   for(Integer x=-10;x<11;x++)
      //     grid.drawLine(Vec3(x, 0, -10) * scale, Vec3(x, 0, 10) * scale);
      //   for(Integer z=-10;z<11;z++)
      //     grid.drawLine(Vec3(-10, 0, z) * scale, Vec3(10, 0, z) * scale);

      //   InlineShader shader = drawing.registerShader(OGLFlatShader());
      //   InlineMaterial mat = shader.getOrCreateMaterial('grey');
      //   mat.setUniform('u_color', Color(0.1, 0.1, 0.1));
      //   vp.gridInstance = InlineInstance('StandaloneGrid', drawing.getRoot(), grid, mat);
      // }

      return true;
    }
    case ViewportDrawPhase_PreDraw: {

      /* the drawing starts with a call to ovrDevice.beginFrame */
      if(this.device.isStereoEnabled()) {
        this.device.beginFrame(0);

        /* start drawing onto our texture render target */
        glBindFramebuffer(GL_FRAMEBUFFER, this.fbo[0]);
      }

      glViewport(0, 0, this.fb_width, this.fb_height);
      glClearColor(this.bgColor.r, this.bgColor.g, this.bgColor.b, this.bgColor.a);
      glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

      return true;

    }
    case ViewportDrawPhase_Draw: {

      InlineDrawing drawing = OGLInlineDrawing_GetInstance();
      this.poses = this.device.getEyePoses();

      glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
      glMatrixMode(GL_PROJECTION);
      glLoadIdentity();
      glMatrixMode(GL_MODELVIEW);
      glLoadIdentity();

      /* for each eye ... */
      for(ovrEyeType i=0; i<ovrEye_Count; i++) {

        ovrEyeType eye = this.desc.EyeRenderOrder[i];

        if(this.device.isStereoEnabled())
          glViewport(eye == ovrEye_Left ? 0 : this.fb_width / 2, 0, this.fb_width / 2, this.fb_height);
        
        glLoadIdentity();

        Xfo camXfo;
        camXfo.ori = this.poses[eye].Orientation;
        camXfo.ori = this.turnOffset * camXfo.ori;

        InlineCamera camera = vp.getCamera();
        if(eye == ovrEye_Left) {
          Vec3 xAxis = camXfo.ori.getXaxis();
          Vec3 yAxis = camXfo.ori.getYaxis();
          Vec3 zAxis = xAxis.cross(Vec3(0.0,1.0,0.0)).unit();
          this.walkOffset += camera.currLinearVelocity.x * xAxis;
          this.walkOffset += camera.currLinearVelocity.y * yAxis;
          this.walkOffset += camera.currLinearVelocity.z * zAxis;

          Quat angularDelta;
          angularDelta.setFromAxisAndAngle(Vec3(0.0, 1.0, 0.0), camera.currAngularVelocity.x);
          this.turnOffset = angularDelta * this.turnOffset;
          // let's not adjust along the x axis
          // angularDelta.setFromAxisAndAngle(Vec3(1.0, 0.0, 0.0), camera.currAngularVelocity.y);
          // this.turnOffset = this.turnOffset * angularDelta;
        }

        camXfo.tr = this.poses[eye].Position * this.poseScale + this.walkOffset;

        if(eye == ovrEye_Left)
          this.worldXfo = camXfo;
        
        camera.xfo = camXfo;
        if(this.device.isStereoEnabled())
          camera.projection = this.device.getProjection(eye, camera.nearDistance, camera.farDistance, true);
        else
          camera.projection.setNull();

        /* finally draw the scene for this eye */
        drawing.draw(context);

        if(!this.device.isStereoEnabled())
          break;
      }
      
      return true;

    }
    case ViewportDrawPhase_PostDraw: {

      vp.responsibleForSwappingBuffers = this.device.isStereoEnabled();
      if(!this.device.isStereoEnabled())
        return false;

      glBindFramebuffer(GL_FRAMEBUFFER, 0);

      glViewport(0, 0, vp.dimensions.x, vp.dimensions.y);
      glClearColor(this.bgColor.r, this.bgColor.g, this.bgColor.b, this.bgColor.a);
      glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

      this.device.endFrame(this.poses, this.fb_ovr_tex);

      return true;

    }
  }
  return false;
}
