/*
 *  Copyright 2010-2014 Fabric Software Inc. All rights reserved.
 */

object ovrGLTextureBuffer;
object ovrGLDepthBuffer;
object ovrGLMirrorTexture;

object ovrDevice {
  /// \internal
  ovrSession session;
  /// \internal
  Boolean configured;
  /// \internal
  Boolean stereoEnabled;
  /// \internal
  ovrGLTextureBuffer textureBuffers[];
  /// \internal
  ovrGLDepthBuffer depthBuffers[];
  /// \internal
  ovrGLMirrorTexture mirrorTextures[];
};

alias Integer ovrTrackingCap;

/// constructor using the first available device
function ovrDevice() {
  this.construct(0);
}

/// internal
function ovrDevice.construct!(Index index) = "ovrDevice_Construct";

/// returns true if this device is valud
function Boolean ovrDevice.valid() {
  Data NULL;
  return this.session.handle != NULL;
}

/// default destructor
function ~ovrDevice() = "ovrDevice_Destruct";

///----------------------------------------
/// OVR_CAPI_0_8_0.h
///-----------------------------------------------------------------------------------------------------------------------------------------------------

/// returns the full description of this device
function ovrDescription ovrDevice.getDescription() = "ovrDevice_GetDescription";

/// returns true if stereo is enabled on this device
function Boolean ovrDevice.isStereoEnabled() {
  return this.stereoEnabled;
}

/// Provides information about the last error.
function String ovrDevice.getLastError() = "ovrDevice_GetLastError";

/// Returns the version string representing the LibOVRRT version.
function String ovrDevice.getVersionString() = "ovrDevice_GetVersionString";

/// Writes a message string to the LibOVR tracing mechanism (if enabled).
function ovrDevice.traceMessage!(ovrLogLevel level, String message) = "ovrDevice_TraceMessage";

/// Re-centers the sensor position and orientation.
///
/// This resets the (x,y,z) positional components and the yaw orientation component.
/// The Roll and pitch orientation components are always determined by gravity and cannot
/// be redefined. All future tracking will report values relative to this new reference position.
function ovrDevice.recenterPose!() = "ovrDevice_RecenterPose";

/// Returns tracking state reading based on the specified absolute system time.
///
/// Pass an absTime value of 0.0 to request the most recent sensor reading. In this case
/// both PredictedPose and SamplePose will have the same value.
///
/// This may also be used for more refined timing of front buffer rendering logic, and so on.
/// This may be called by multiple threads.
///
/// \param[in] session Specifies an ovrSession previously returned by ovr_Create.
/// \param[in] absTime Specifies the absolute future time to predict the return
///            ovrTrackingState value. Use 0 to request the most recent tracking state.
/// \param[in] latencyMarker Specifies that this call is the point in time where
///            the "App-to-Mid-Photon" latency timer starts from. If a given ovrLayer
///            provides "SensorSampleTimestamp", that will override the value stored here.
/// \return Returns the ovrTrackingState that is predicted for the given absTime.
///
/// \see ovrTrackingState, ovr_GetEyePoses, ovr_GetTimeInSeconds
///
function ovrTrackingState ovrDevice.getTrackingState(Float64 absTime, Boolean latencyMarker) = "ovrDevice_GetTrackingState";

/// Returns the most recent input state for controllers, without positional tracking info.
/// Developers can tell whether the same state was returned by checking the PacketNumber.
function Boolean ovrDevice.getInputState(ovrControllerType controllerTypeMask, io ovrInputState state) = "ovrDevice_GetInputState";

/// Turns on vibration of the given controller.
///
/// To disable vibration, call ovr_SetControllerVibration with an amplitude of 0.
/// Vibration automatically stops after a nominal amount of time, so if you want vibration 
/// to be continuous over multiple seconds then you need to call this function periodically.
function Boolean ovrDevice.setControllerVibration!(ovrControllerType controllerTypeMask, Float32 frequency, Float32 amplitude) = "ovrDevice_SetControllerVibration";

/// Calculates the recommended viewport size for rendering a given eye within the HMD
/// with a given FOV cone.
///
/// Higher FOV will generally require larger textures to maintain quality.
/// Apps packing multiple eye views together on the same texture should ensure there are
/// at least 8 pixels of padding between them to prevent texture filtering and chromatic
/// aberration causing images to leak between the two eye views.
function ovrSize ovrDevice.getFovTextureSize(ovrEyeType eye, ovrFovPort fov, Float32 pixelsPerDisplayPixel) = "ovrDevice_GetFovTextureSize";

/// Computes the distortion viewport, view adjust, and other rendering parameters for
/// the specified eye.
///
function ovrEyeRenderDesc ovrDevice.getRenderDesc(ovrEyeType eye, ovrFovPort fov) = "ovrDevice_GetRenderDesc";

/// Submits layers for distortion and display.
/// Overload taking a single ovrLayerEyeFov
///
/// ovr_SubmitFrame triggers distortion and processing which might happen asynchronously.
/// The function will return when there is room in the submission queue and surfaces
/// are available. Distortion might or might not have completed.
function Boolean ovrDevice.submitFrame!(UInt32 frameIndex, ovrViewScaleDesc scale, ovrLayerEyeFov layer) = "ovrDevice_SubmitFrame_ovrLayerEyeFov";

/// Gets the time of the specified frame midpoint.
///
/// Predicts the time at which the given frame will be displayed. The predicted time 
/// is the middle of the time period during which the corresponding eye images will 
/// be displayed. 
///
/// The application should increment frameIndex for each successively targeted frame,
/// and pass that index to any relevent OVR functions that need to apply to the frame
/// identified by that index.
///
/// This function is thread-safe and allows for multiple application threads to target
/// their processing to the same displayed frame.
/// 
/// \param[in] session Specifies an ovrSession previously returned by ovr_Create.
/// \param[in] frameIndex Identifies the frame the caller wishes to target.
///            A value of zero returns the next frame index.
/// \return Returns the absolute frame midpoint time for the given frameIndex.
/// \see ovr_GetTimeInSeconds
///
function Float64 ovrDevice.getPredictedDisplayTime(SInt64 frameIndex) = "ovrDevice_GetPredictedDisplayTime";

/// Returns global, absolute high-resolution time in seconds.
///
/// The time frame of reference for this function is not specified and should not be
/// depended upon.
function Float64 ovrDevice.getTimeInSeconds() = "ovrDevice_GetTimeInSeconds";

/// Should be called when the headset is placed on a new user.
/// Previously named ovrHmd_ResetOnlyBackOfHeadTrackingForConnectConf.
///
/// This may be removed in a future SDK version.
function ovrDevice.resetBackOfHeadTracking!() = "ovrDevice_ResetBackOfHeadTracking";

/// Should be called when a tracking camera is moved.
///
/// This may be removed in a future SDK version.
function ovrDevice.resetMulticameraTracking!() = "ovrDevice_ResetMulticameraTracking";

/// Reads a boolean property.
function Boolean ovrDevice.getBool(String propertyName, Boolean defaultValue) = "ovrDevice_GetBool";

/// Writes or creates a boolean property.
/// If the property wasn't previously a boolean property, it is changed to a boolean property.
function ovrDevice.setBool!(String propertyName, Boolean value) = "ovrDevice_SetBool";

/// Reads an integer property.
function SInt32 ovrDevice.getInt(String propertyName, SInt32 defaultValue) = "ovrDevice_GetInt";

/// Writes or creates an integer property.
/// If the property wasn't previously an integer property, it is changed to an integer property.
function ovrDevice.setInt!(String propertyName, SInt32 value) = "ovrDevice_SetInt";

/// Reads a float property.
function Float32 ovrDevice.getFloat(String propertyName, Float32 defaultValue) = "ovrDevice_GetFloat";

/// Writes or creates a float property.
/// If the property wasn't previously a float property, it is changed to a float property.
function ovrDevice.setFloat!(String propertyName, Float32 value) = "ovrDevice_SetFloat";

/// Reads a float array property.
/// valuesCapacity Specifies the maximum number of elements to write to the values array.
function Float32[] ovrDevice.getFloatArray(String propertyName, UInt32 valuesCapacity) = "ovrDevice_GetFloatArray";

/// Writes or creates a float array property.
function ovrDevice.setFloatArray!(String propertyName, Float32 values[]) = "ovrDevice_SetFloatArray";

/// Reads a string property.
/// Strings are UTF8-encoded and null-terminated.
function String ovrDevice.getString(String propertyName, String defaultValue) = "ovrDevice_GetString";

/// Writes or creates a string property.
/// Strings are UTF8-encoded and null-terminated.
function ovrDevice.setString!(String propertyName, String value) = "ovrDevice_SetString";

///----------------------------------------
/// OVR_CAPI_Util.h
///-----------------------------------------------------------------------------------------------------------------------------------------------------

/// Used to generate projection from ovrEyeDesc::Fov.
function Mat44 ovrDevice.getProjectionMat44(ovrFovPort fov, Float32 znear, Float32 zfar, ovrProjectionModifier projectionModFlags) = "ovrDevice_GetProjectionMat44";

/// Extracts the required data from the result of ovrMatrix4f_Projection.
function ovrTimewarpProjectionDesc ovrDevice.getTimewarpProjectionDescFromProjection(Mat44 projection, ovrProjectionModifier projectionModFlags) = "ovrDevice_GetTimewarpProjectionDescFromProjection";

/// Generates an orthographic sub-projection.
///
/// Used for 2D rendering, Y is down.
function Mat44 ovrDevice.getOrthoSubProjectionMat44(Mat44 projection, Vec2 orthoScale, Float32 orthoDistance, Float32 hmdToEyeViewOffsetX) = "ovrDevice_GetOrthoSubProjectionMat44";

/// Computes offset eye poses based on headPose returned by ovrTrackingState.
function ovrPose[2] ovrDevice.calcEyePoses(ovrPose headPose, Vec3 hmdToEyeViewOffset[2]) = "ovrDevice_CalcEyePoses";

/// Returns the predicted head pose in outHmdTrackingState and offset eye poses in outEyePoses. 
///
/// This is a thread-safe function where caller should increment frameIndex with every frame
/// and pass that index where applicable to functions called on the rendering thread.
/// Assuming outEyePoses are used for rendering, it should be passed as a part of ovrLayerEyeFov.
/// The caller does not need to worry about applying HmdToEyeViewOffset to the returned outEyePoses variables.
///
/// \param[in]  hmd Specifies an ovrHmd previously returned by ovr_Create.
/// \param[in]  frameIndex Specifies the targeted frame index, or 0 to refer to one frame after 
///             the last time ovr_SubmitFrame was called.
/// \param[in]  hmdToEyeViewOffset Can be ovrEyeRenderDesc.HmdToEyeViewOffset returned from 
///             ovr_GetRenderDesc. For monoscopic rendering, use a vector that is the average 
///             of the two vectors for both eyes.
/// \param[in]  latencyMarker Specifies that this call is the point in time where
///             the "App-to-Mid-Photon" latency timer starts from. If a given ovrLayer
///             provides "SensorSampleTimestamp", that will override the value stored here.
/// \param[out] outEyePoses The predicted eye poses.
/// \param[out] outHmdTrackingState The predicted ovrTrackingState. May be NULL, in which case it is ignored.
///
function ovrDevice.getEyePoses(UInt32 frameIndex, Boolean latencyMarker, Vec3 hmdToEyeViewOffset[2], io ovrPose outEyePoses[2], io ovrTrackingState outHmdTrackingState) = "ovrDevice_GetEyePoses";
